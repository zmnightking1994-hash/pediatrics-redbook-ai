import streamlit as st
import cv2
import pandas as pd
import numpy as np
import tensorflow as tf

# Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©
st.set_page_config(page_title="Pediatrics AI Radiologist", layout="wide")

st.markdown("""
    <style>
    .reportview-container { background: #f0f2f6; }
    .stAlert { border-radius: 10px; border: 1px solid #d1d8e0; }
    h1 { color: #2c3e50; text-align: center; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ©º Ù…Ø³Ø§Ø¹Ø¯ Ø·Ø¨ÙŠØ¨ Ø§Ù„Ø£Ø·ÙØ§Ù„ Ø§Ù„Ø°ÙƒÙŠ (Red Book AI)")

# --- Ù…Ø­Ø±Ùƒ Ø§Ù„ÙÙ„ØªØ±Ø© Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ø°ÙƒÙŠ ---
def clean_medical_text(text):
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø¯ÙˆÙŠØ© ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªÙ‡Ù… Ø§Ù„Ø·Ø¨ÙŠØ¨ ÙÙŠ Ø§Ù„Ù€ Red Book
    important_keywords = [
        "Amoxicillin", "Ampicillin", "Ceftriaxone", "Penicillin", "Azithromycin", 
        "dose", "mg/kg", "days", "Duration", "IV", "Oral", "Treatment"
    ]
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙˆÙƒÙ„Ø§Ù… Ø§Ù„Ù€ HIV ØºÙŠØ± Ø°ÙŠ Ø§Ù„ØµÙ„Ø© Ø¨Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
    sentences = text.split('.')
    filtered_sentences = []
    
    for s in sentences:
        # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ HIV Ø¥Ø°Ø§ Ù„Ù… Ù†ÙƒÙ† Ù†Ø¨Ø­Ø« Ø¹Ù†Ù‡Ø§
        if "HIV" in s or "clinicalinfo" in s:
            continue
        # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø¯ÙˆÙŠØ© Ø£Ùˆ Ø¬Ø±Ø¹Ø§Øª
        if any(key.lower() in s.lower() for key in important_keywords):
            filtered_sentences.append(s.strip())
            
    return filtered_sentences[:5] # Ø¥Ø±Ø¬Ø§Ø¹ Ø£Ù‡Ù… 5 Ø¬Ù…Ù„ Ø¹Ù„Ø§Ø¬ÙŠØ© ÙÙ‚Ø·

# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ---
uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ø§Ù„Ø£Ø´Ø¹Ø© Ù‡Ù†Ø§...", type=["jpg", "png", "jpeg"])

if uploaded_file:
    col1, col2 = st.columns([1, 1.2])
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø±Ø§Ø±ÙŠ
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, 1)
    
    with col1:
        st.subheader("ğŸ” Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ØµØ±ÙŠ (Heatmap)")
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        heatmap = cv2.applyColorMap(cv2.equalizeHist(gray), cv2.COLORMAP_JET)
        st.image(cv2.addWeighted(img, 0.6, heatmap, 0.4, 0), use_container_width=True)

    with col2:
        st.subheader("ğŸ“‹ Ø§Ù„ØªØ´Ø®ÙŠØµ ÙˆØ§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø§Ù„Ø¹Ù„Ø§Ø¬ÙŠ")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ«Ø§ÙØ© (ØªØ¨Ø³ÙŠØ·Ø§Ù‹)
        avg_density = np.mean(gray)
        pathogen = "Streptococcus pneumoniae" if avg_density > 130 else "Mycoplasma pneumoniae"
        
        st.error(f"âš ï¸ Ø§Ù„Ù…Ø³Ø¨Ø¨ Ø§Ù„Ù…Ø±Ø¬Ø­: {pathogen}")
        
        # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø§Ù„Ù…Ø¹Ø¯Ù„
        try:
            db = pd.read_excel("pneumonia_reference.xlsx")
            raw_data = db[db['Pathogen'] == pathogen].iloc[0]['Treatment Snippet']
            page_num = db[db['Pathogen'] == pathogen].iloc[0]['Page']
            
            st.info(f"ğŸ“– Ù…Ø±Ø¬Ø¹ Ø§Ù„ÙƒØªØ§Ø¨: ØµÙØ­Ø© {page_num}")
            st.markdown("### ğŸ’Š Ø§Ù„Ø¬Ø±Ø¹Ø§Øª ÙˆØ§Ù„Ø¹Ù„Ø§Ø¬ Ø§Ù„Ù…Ù‚ØªØ±Ø­:")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø¹Ù„Ø§Ø¬ Ø§Ù„Ù…ÙÙ„ØªØ±
            clinical_tips = clean_medical_text(raw_data)
            
            if clinical_tips:
                for tip in clinical_tips:
                    st.success(f"**{tip}**")
            else:
                # ÙÙŠ Ø­Ø§Ù„ Ù„Ù… ÙŠØ¬Ø¯ Ø¬Ù…Ù„ Ù…ÙÙ„ØªØ±Ø©ØŒ ÙŠØ¹Ø±Ø¶ Ù†ØµØ§Ù‹ Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹ Ø¯Ù‚ÙŠÙ‚Ø§Ù‹ Ø·Ø¨ÙŠØ§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø¨Ø¨
                if "Streptococcus" in pathogen:
                    st.warning("Ø§Ù„Ø¬Ø±Ø¹Ø© Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ©: Amoxicillin (80â€“90 mg/kg per day in 2 divided doses)")
                else:
                    st.warning("Ø§Ù„Ø¬Ø±Ø¹Ø© Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ©: Azithromycin (10 mg/kg on day 1, then 5 mg/kg for 4 days)")
                    
        except:
            st.error("ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù pneumonia_reference.xlsx")

st.caption("Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ±Ø´Ø§Ø¯ÙŠ ÙÙ‚Ø·. Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø³Ø±ÙŠØ±ÙŠ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ø·Ø¨ÙŠØ¨.")
